{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neural_processes.model import  Encoder, LatentDecoder, Aggregator, LatentNP\n",
    "from neural_processes.model.attention import Attention, MLP\n",
    "from dataset import GPCurvesReader\n",
    "from neural_processes.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_samples, x_size, y_size = 100, 10, 1, 1\n",
    "num_targets = 5\n",
    "context_X = torch.randn(batch_size, num_samples, x_size)\n",
    "context_y = torch.randn(batch_size, num_samples, y_size)\n",
    "target_X = torch.randn(batch_size, num_targets, x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention()\n",
    "r= attn(query=context_X, key=context_X, value=context_y)\n",
    "print(r.shape)\n",
    "output = attn(query=target_X, key=context_X, value=r)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Processes \n",
    "Latent distribution to model functional uncertainty: $z = \\mathcal{N}(\\mu(r), I\\sigma(r))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config/np_config.yaml\") as file:\n",
    "        cfg = OmegaConf.load(file)\n",
    "\n",
    "encoder_num_layers = cfg.encoder.num_layers\n",
    "encoder_num_units = cfg.encoder.num_units\n",
    "encoder_activation_cls = cfg.encoder.activation_cls\n",
    "decoder_num_layers = cfg.decoder.num_layers\n",
    "decoder_num_units = cfg.decoder.num_units\n",
    "decoder_activation_cls = cfg.decoder.activation_cls\n",
    "aggregator_num_layers = cfg.aggregator.num_layers\n",
    "aggregator_num_units = cfg.aggregator.num_units\n",
    "aggregator_activation_cls = cfg.aggregator.activation_cls\n",
    "r_dim = cfg.r_dim\n",
    "y_size = cfg.dataset.y_size\n",
    "x_size = cfg.dataset.x_size\n",
    "max_num_context = cfg.dataset.max_num_context\n",
    "batch_size = cfg.dataset.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d regression dataset, sampled from a GP\n",
    "data_train = GPCurvesReader(batch_size=batch_size, max_num_context=max_num_context)\n",
    "data_test = GPCurvesReader(batch_size=batch_size, max_num_context=max_num_context, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_encoder = Encoder(x_size=x_size, r_dim=r_dim, y_size=y_size, num_layers=encoder_num_layers, num_units=encoder_num_units, activation_cls=encoder_activation_cls)\n",
    "latent_decoder = LatentDecoder(x_size=x_size, r_dim=r_dim, y_size=y_size, num_layers=decoder_num_layers, num_units=decoder_num_units, activation_cls=decoder_activation_cls)\n",
    "aggregator = Aggregator(r_dim=r_dim, num_layers=aggregator_num_layers, num_units=aggregator_num_units, activation_cls=aggregator_activation_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_np = LatentNP(encoder_num_layers=encoder_num_layers,\n",
    "                 encoder_num_units=encoder_num_units,\n",
    "                 encoder_activation_cls=encoder_activation_cls,\n",
    "                 decoder_num_layers=decoder_num_layers, \n",
    "                 decoder_num_units=decoder_num_units,\n",
    "                 decoder_activation_cls=decoder_activation_cls,\n",
    "                 agggreagtor_num_layers=aggregator_num_layers,\n",
    "                 agggreagtor_num_units=aggregator_num_units,\n",
    "                 agggreagtor_activation_cls=aggregator_activation_cls,\n",
    "                 r_dim=r_dim,\n",
    "                 x_size=x_size,\n",
    "                 y_size=y_size)\n",
    "latent_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_np = train(config=cfg, model=latent_np, data_train=data_train, data_test=data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(latent_np, 'neural_processes/trained_model/np_elbo.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
